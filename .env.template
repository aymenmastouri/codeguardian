# =============================================================================
# Codeguardian Production Configuration
# =============================================================================

# =============================================================================
# Project Structure Configuration
# =============================================================================
PROJECT_PATH=C:\project-backend
INPUTS_PATH=C:\inputs
BUG_DESC_FILE=bug-desc.txt
BUG_LOG_FILE=bug-log.txt
# =============================================================================
# AI Model Configuration
# =============================================================================
# Primary LLM for CrewAI agents
MODEL=openai/kaitchup/Llama-3.3-70B-Instruct-AutoRound-GPTQ-4bit
API_BASE=http://bmf-ai.apps.ce.capgemini.com/chat/v1
OPENAI_API_KEY=test

# Local embeddings via Ollama (for semantic search)
OLLAMA_BASE_URL=http://localhost:11434
EMBED_MODEL=nomic-embed-text:latest

CHROMA_DIR=C:\projects\codeguardian\.cache\.chroma

FORCE_REINDEX=0
AUTO_INDEX_NO_GIT=0

INDEX_MAX_FILES_BACKEND=4000
INDEX_MAX_FILES_FRONTEND=4000
INDEX_LOCK_TIMEOUT_S=300


# optional tuning:
CHUNK_CHARS=1800
CHUNK_OVERLAP=200
MAX_FILE_BYTES=2000000


CREWAI_TRACING_ENABLED=true
